{
    "exp_dir": "exp_out/feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42",
    "exp_name": "feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42",
    "seed": 42,
    "run_joint": false,
    "use_cached_data": false,
    "claim_decomposition": "generation",
    "use_fever_training": false,
    "model": "EncDec",
    "max_seq_len": 512,
    "max_answer_choice_length": 150,
    "origin_model": "google/flan-t5-xl",
    "load_weight": "models/TabVer_FlanT5-xl/finish.pt",
    "nli_file_path": "deberta-v3-nli_zero_shot_False_probabilities.json",
    "gradient_checkpointing": true,
    "dataset": "feverous",
    "stratified_sampling": false,
    "num_classes": 3,
    "num_samples": 128,
    "batch_size": 4,
    "eval_batch_size": 32,
    "num_workers": 1,
    "negative_samples_ratio": 1,
    "use_retrieved_evidence": true,
    "num_retrieved_evidence": 5,
    "neg_token": "No",
    "nei_token": "NOT ENOUGH INFO",
    "zero_shot": false,
    "few_shot": true,
    "randomize_templates": true,
    "template_setting_id": 1,
    "num_questions": 1,
    "num_templates": 1,
    "question_id": -1,
    "template_id": -1,
    "alignment_model": "bert_finetuned_paper",
    "matching_method": "mwmf",
    "sentence_transformer": "sentence-transformers/all-mpnet-base-v2",
    "max_chunks": 6,
    "alignment_mode": "awesomealign",
    "loose_matching": false,
    "dynamic_parsing": true,
    "dynamic_parsing_nei_threshold": 0.5,
    "use_tab_qa": "all_table_llm",
    "qg_model": "models/question_generation_Mistral-7B-OpenOrca_train_all_prompt_False_2024-05-01-01-06_seed_42/checkpoint-140",
    "qa_model": "models/question_answering_Mistral-7B-OpenOrca_all_table_llm_all_train_all_prompt_False_2024-05-01-15-40_seed_42/checkpoint-140",
    "decomposition_model": "models/claim_decomposition_Mistral-7B-OpenOrca_train_all_prompt_False_2024-04-09-12-58/checkpoint-50",
    "permissable_operators": "all",
    "debug": false,
    "compute_precision": "32",
    "compute_strategy": "none",
    "num_steps": 2000,
    "grad_accum_factor": 8,
    "val_check_interval": 250,
    "eval_before_training": false,
    "save_model": false,
    "save_step_interval": 20000,
    "mc_loss": 1,
    "unlikely_loss": 1,
    "length_norm": 1,
    "split_choices_at": 10,
    "split_option_at_inference": true,
    "optimizer": "adamw",
    "lr": 1e-05,
    "trainable_param_names": ".*",
    "scheduler": "linear_decay_with_warmup",
    "warmup_ratio": 0.06,
    "weight_decay": 0.3,
    "scale_parameter": true,
    "grad_clip_norm": 1,
    "train_pred_file": "exp_out/feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42/train_pred.txt",
    "dev_pred_file": "exp_out/feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42/dev_pred.txt",
    "dev_score_file": "exp_out/feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42/dev_scores.json",
    "test_pred_file": "exp_out/feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42/test_pred.txt",
    "test_score_file": "exp_out/feverous/environment_local_model_flant5_xl_trained_alignment_5_ev_concat_all_table_mistralorca_trained_decomposition_ops_all_updated_samples_128/42/test_scores.json"
}
